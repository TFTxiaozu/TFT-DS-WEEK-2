{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "train = pd.read_csv('../Assignment1-3/data/train.csv')\n",
    "test = pd.read_csv('../Assignment1-3/data/test.csv')\n",
    "subm = pd.read_csv('../Assignment1-3/data/sample_submission.csv')\n",
    "\n",
    "trainingdata = train.comment_text\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "test_labels = pd.read_csv('../Assignment1-3/data/test_labels.csv')\n",
    "test_labels_filter = test_labels[test_labels['toxic']>-1]\n",
    "test_filter = test[test.id.isin(test_labels_filter.id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成TFIDF向量，查看每个类下TFIDF值Top20的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 189460)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vect.fit_transform(trainingdata)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 189460)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf[0].toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_dict = {}\n",
    "tf_idf_count = {}\n",
    "for targetid, target in enumerate(labels):\n",
    "    tf_idf_dict[target] = np.zeros((1, X_train_tfidf.shape[1]))\n",
    "    tf_idf_count[target] = 0\n",
    "for i in range(X_train_tfidf.shape[0]):\n",
    "    for targetid, target in enumerate(labels):\n",
    "        if train[target][i] == 1:\n",
    "            tf_idf_dict[target] += X_train_tfidf[i].toarray()\n",
    "            tf_idf_count[target] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for key, val in vect.vocabulary_.items():\n",
    "    mapping[val] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "\twikipedia\n",
      "\tsuck\n",
      "\tstupid\n",
      "\tbitch\n",
      "\tass\n",
      "\tdon\n",
      "\tlike\n",
      "\tshit\n",
      "\tfucking\n",
      "\tfuck\n",
      "severe_toxic\n",
      "\tfaggot\n",
      "\tcunt\n",
      "\tdick\n",
      "\tasshole\n",
      "\tass\n",
      "\tsuck\n",
      "\tshit\n",
      "\tbitch\n",
      "\tfucking\n",
      "\tfuck\n",
      "obscene\n",
      "\tfaggot\n",
      "\tcunt\n",
      "\tdick\n",
      "\tasshole\n",
      "\tsuck\n",
      "\tass\n",
      "\tbitch\n",
      "\tshit\n",
      "\tfucking\n",
      "\tfuck\n",
      "threat\n",
      "\tll\n",
      "\trape\n",
      "\thope\n",
      "\tshit\n",
      "\tass\n",
      "\tgoing\n",
      "\tfuck\n",
      "\tfucking\n",
      "\tkill\n",
      "\tdie\n",
      "insult\n",
      "\tfaggot\n",
      "\tidiot\n",
      "\tstupid\n",
      "\tasshole\n",
      "\tass\n",
      "\tsuck\n",
      "\tshit\n",
      "\tbitch\n",
      "\tfucking\n",
      "\tfuck\n",
      "identity_hate\n",
      "\tlike\n",
      "\tjew\n",
      "\tass\n",
      "\tbitch\n",
      "\tshit\n",
      "\tfucking\n",
      "\tnigger\n",
      "\tfaggot\n",
      "\tfuck\n",
      "\tgay\n"
     ]
    }
   ],
   "source": [
    "tf_idf_numbers = {}\n",
    "for targetid, target in enumerate(labels):\n",
    "    print (target)\n",
    "    tf_idf_numbers[targetid] = tf_idf_dict[target]/tf_idf_count[target]\n",
    "    #print(len(tf_idf_numbers[targetid]))\n",
    "    #print(len(tf_idf_numbers[targetid][0]))\n",
    "    for x in np.argsort(tf_idf_numbers[targetid][0])[-10:]:\n",
    "        print(\"\\t\"+mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Practice\n",
    "\n",
    "（1）在trainingdata上训练Logistic Regression模型并预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic ROC AUC: 0.9853635693332268\n",
      "severe_toxic ROC AUC: 0.992690155863523\n",
      "obscene ROC AUC: 0.993793914320817\n",
      "threat ROC AUC: 0.9955089227434588\n",
      "insult ROC AUC: 0.9882714531617584\n",
      "identity_hate ROC AUC: 0.9907858102863504\n",
      "mean column-wise ROC AUC: 0.9910689709515225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lrs = []\n",
    "rocs = []\n",
    "for targetid, target in enumerate(labels):\n",
    "    lr = Pipeline([('vect', vect), ('clf', LogisticRegression())])\n",
    "    lr = lr.fit(trainingdata, train[target])\n",
    "    #lr = LogisticRegression().fit(X_train_tfidf, train[target])\n",
    "    lrs.append(lr)\n",
    "    #pred_training = lr.predict_proba(X_train_tfidf)[:,1]\n",
    "    pred_training = lr.predict_proba(trainingdata)[:,1]\n",
    "    roc = roc_auc_score(train[target], pred_training)\n",
    "    print(target, 'ROC AUC:', roc)\n",
    "    rocs.append(roc)\n",
    "print('mean column-wise ROC AUC:', np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）在test_filter上计算ROC AUC指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic ROC AUC: 0.9005865638510603\n",
      "severe_toxic ROC AUC: 0.9750375847544405\n",
      "obscene ROC AUC: 0.9132678872099901\n",
      "threat ROC AUC: 0.9390919042720474\n",
      "insult ROC AUC: 0.9109509279959951\n",
      "identity_hate ROC AUC: 0.9792107370272192\n",
      "mean column-wise ROC AUC: 0.9637132862096275\n"
     ]
    }
   ],
   "source": [
    "for targetid, target in enumerate(labels):\n",
    "    X_test_tfidf = vect.transform(test_filter.comment_text)\n",
    "    pred_testing = lr.predict_proba(X_test_tfidf)[:,1]\n",
    "    roc = roc_auc_score(test_labels_filter[target], pred_testing)\n",
    "    print(target, 'ROC AUC:', roc)\n",
    "    rocs.append(roc)\n",
    "print('mean column-wise ROC AUC:', np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）分析模型属于High Variance还是High Bias，抑或是二者都有？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> High Bias: Training Error and Testing Error are both large\n",
    "\n",
    "> High Variance: The difference between Training Error and Testing Error is large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Practice\n",
    "\n",
    "对trainingdata做5折交叉验证，计算training的平均ROC AUC指标、dev的平均ROC AUC指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Column-wise ROC AUC: 0.9908182751983459\n",
      "Dev Mean Column-wise ROC AUC: 0.9764494301108031\n",
      "Train Mean Column-wise ROC AUC: 0.9913464681077744\n",
      "Dev Mean Column-wise ROC AUC: 0.9732581142104844\n",
      "Train Mean Column-wise ROC AUC: 0.9911611490342116\n",
      "Dev Mean Column-wise ROC AUC: 0.9713320292875582\n",
      "Train Mean Column-wise ROC AUC: 0.990984704961287\n",
      "Dev Mean Column-wise ROC AUC: 0.9728900755004672\n",
      "Train Mean Column-wise ROC AUC: 0.9906165421689256\n",
      "Dev Mean Column-wise ROC AUC: 0.9777218980483355\n",
      "5-Fold Train Mean Column-wise ROC AUC: 0.990985427894109\n",
      "5-Fold Dev Mean Column-wise ROC AUC: 0.9743303094315298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "rocs_train_folds = []\n",
    "rocs_dev_folds = []\n",
    "for train_indices, dev_indices in k_fold.split(train):\n",
    "    X_train = [trainingdata[i] for i in train_indices]\n",
    "    X_dev = [trainingdata[i] for i in dev_indices]\n",
    "    for label_id, label in enumerate(labels):\n",
    "        rocs_train = []\n",
    "        rocs_dev = []\n",
    "        Y_train = [train[label][i] for i in train_indices]\n",
    "        Y_dev = [train[label][i] for i in dev_indices]\n",
    "        #print(len(X_train), len(Y_train), len(X_test), len(Y_test))\n",
    "        lr.fit(X_train, Y_train)  \n",
    "        Y_train_predicted = lr.predict_proba(X_train)[:,1]\n",
    "        roc = roc_auc_score(Y_train, Y_train_predicted)\n",
    "        rocs_train.append(roc)\n",
    "        Y_dev_predicted = lr.predict_proba(X_dev)[:,1]\n",
    "        roc = roc_auc_score(Y_dev, Y_dev_predicted)\n",
    "        rocs_dev.append(roc)\n",
    "    rocs_train_fold = np.mean(rocs_train)\n",
    "    rocs_train_folds.append(rocs_train_fold)\n",
    "    print('Train Mean Column-wise ROC AUC:', rocs_train_fold)\n",
    "    rocs_dev_fold = np.mean(rocs_dev)\n",
    "    rocs_dev_folds.append(rocs_dev_fold)\n",
    "    print('Dev Mean Column-wise ROC AUC:', rocs_dev_fold)\n",
    "print('5-Fold Train Mean Column-wise ROC AUC:', np.mean(rocs_train_folds))\n",
    "print('5-Fold Dev Mean Column-wise ROC AUC:', np.mean(rocs_dev_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Practice\n",
    "\n",
    "（1）对vect\\__max_df，vect\\__max_features，vect\\__ngram_range，clf\\__C在trainingdata上进行网格搜索调参。\n",
    "\n",
    "（2）在gridsearch时使用5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Cs = np.logspace(-3, -1, 2)\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75),\n",
    "    'vect__max_features': (None, 20000),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),  # 1-gram or 2-grams or 3-grams\n",
    "    'clf__C': tuple(Cs)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=50)\n",
    "\n",
    "Y_devs = []\n",
    "for train_indices, dev_indices in k_fold.split(train):\n",
    "    X_dev = [trainingdata[i] for i in dev_indices]\n",
    "    for label_id, label in enumerate(labels):\n",
    "        Y_dev = [train[label][i] for i in dev_indices]\n",
    "        Y_devs.append(Y_dev)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing grid search for toxic  ...\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75), 'vect__max_features': (None, 20000), 'vect__ngram_range': ((1, 2), (1, 3)), 'clf__C': (0.001, 0.1)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   47.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 49.107s\n",
      "\n",
      "toxic Best ROC AUC: 0.927\n",
      "toxic Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 20000\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\n",
      "Performing grid search for severe_toxic  ...\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75), 'vect__max_features': (None, 20000), 'vect__ngram_range': ((1, 2), (1, 3)), 'clf__C': (0.001, 0.1)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   47.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 48.299s\n",
      "\n",
      "severe_toxic Best ROC AUC: 0.977\n",
      "severe_toxic Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\n",
      "Performing grid search for obscene  ...\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75), 'vect__max_features': (None, 20000), 'vect__ngram_range': ((1, 2), (1, 3)), 'clf__C': (0.001, 0.1)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   53.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 55.323s\n",
      "\n",
      "obscene Best ROC AUC: 0.966\n",
      "obscene Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\n",
      "Performing grid search for threat  ...\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75), 'vect__max_features': (None, 20000), 'vect__ngram_range': ((1, 2), (1, 3)), 'clf__C': (0.001, 0.1)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   50.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 51.472s\n",
      "\n",
      "threat Best ROC AUC: 0.980\n",
      "threat Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 20000\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\n",
      "Performing grid search for insult  ...\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75), 'vect__max_features': (None, 20000), 'vect__ngram_range': ((1, 2), (1, 3)), 'clf__C': (0.001, 0.1)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   50.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 52.318s\n",
      "\n",
      "insult Best ROC AUC: 0.948\n",
      "insult Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 20000\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\n",
      "Performing grid search for identity_hate  ...\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75), 'vect__max_features': (None, 20000), 'vect__ngram_range': ((1, 2), (1, 3)), 'clf__C': (0.001, 0.1)}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   44.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 45.190s\n",
      "\n",
      "identity_hate Best ROC AUC: 0.921\n",
      "identity_hate Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "grid_search = GridSearchCV(lr, parameters, n_jobs=-1, verbose=1, cv=5, scoring='roc_auc')\n",
    "\n",
    "best_rocs = []\n",
    "best_models = []\n",
    "for label_id, label in enumerate(labels):\n",
    "    print()\n",
    "    print(\"Performing grid search for\", label, \" ...\")\n",
    "    print(\"parameters:\")\n",
    "    print(parameters)\n",
    "    t0 = time()\n",
    "    #grid_search.fit(trainingdata, train[label])\n",
    "    grid_search.fit(X_dev, Y_devs[label_id])\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    print(label, \"Best ROC AUC: %0.3f\" % grid_search.best_score_)\n",
    "    best_rocs.append(grid_search.best_score_)\n",
    "    print(label, \"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    best_models.append(grid_search.best_estimator_)\n",
    "    for param_name in sorted(parameters.keys()): \n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）使用最优参数得到的模型，在test_filter上生成测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic ROC AUC: 0.9202435513887415\n",
      "severe_toxic ROC AUC: 0.9712177905925735\n",
      "obscene ROC AUC: 0.9406179374530438\n",
      "threat ROC AUC: 0.9447219613288513\n",
      "insult ROC AUC: 0.9253114732382458\n",
      "identity_hate ROC AUC: 0.9263522781642128\n",
      "mean column-wise ROC AUC: 0.9380774986942781\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for labelid, label in enumerate(labels): \n",
    "    pred_filter = best_models[labelid].predict_proba(test_filter.comment_text)[:,1]\n",
    "    roc = roc_auc_score(test_labels_filter[label], pred_filter)\n",
    "    print(label, 'ROC AUC:', roc)\n",
    "    rocs.append(roc)\n",
    "print('mean column-wise ROC AUC:', np.mean(rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
